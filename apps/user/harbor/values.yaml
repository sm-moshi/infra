# PostgreSQL per-app cluster configuration
postgresql:
  enabled: true
  instances: 1
  imageName: ghcr.io/cloudnative-pg/postgresql:18.1-system-trixie
  storage:
    size: 40Gi
    # ZFS dataset rpool/k8s/pgdata with 16K recordsize - optimized for PostgreSQL small random I/O
    storageClass: proxmox-csi-zfs-nvme-fast-retain
  walStorage:
    size: 10Gi
    # ZFS dataset rpool/k8s/pgwal with 128K recordsize - optimized for PostgreSQL WAL sequential writes
    storageClass: proxmox-csi-zfs-nvme-general-retain
  backup:
    enabled: true
    # CNPG requires a 6-field cron with seconds
    schedule: "0 0 2 * * *"
    target: prefer-standby
    immediate: false
  resources:
    requests:
      memory: 1Gi
      cpu: 200m # PostgreSQL mostly I/O-bound, allow CPU bursting
    limits:
      memory: 3Gi # Keep headroom on 6-10Gi workers
      cpu: 2 # Allow bursts during VACUUM/index builds
  tolerations: []
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 80
        preference:
          matchExpressions:
          - key: topology.kubernetes.io/zone
            operator: In
            values: [ "pve-01" ]
      - weight: 60
        preference:
          matchExpressions:
          - key: topology.kubernetes.io/zone
            operator: In
            values: [ "pve-02" ]

# One-off, opt-in DB migration from the per-app CNPG cluster (harbor-postgres) to
# the shared cnpg-main cluster. Keep disabled unless you are actively migrating.
dbMigration:
  enabled: false
  image:
    repository: dhi.io/postgres
    tag: 18.1-debian13@sha256:086748e4e33806af10483b2dd4bc287d7102a8cc3d11d73f5cad9886c02f3b87
    pullPolicy: IfNotPresent
  imagePullSecrets:
  - name: kubernetes-dhi
  source:
    host: harbor-postgres-rw.apps.svc.cluster.local
    port: "5432"
    database: harbor
    userSecret:
      name: harbor-postgres-superuser
      usernameKey: username
      passwordKey: password
  target:
    host: cnpg-main-rw.apps.svc.cluster.local
    port: "5432"
    database: harbor
    userSecret:
      name: cnpg-main-superuser
      usernameKey: username
      passwordKey: password

harbor:
  expose:
    type: ingress
    tls:
      enabled: true
      certSource: secret
      secret:
        secretName: wildcard-m0sh1-cc
    ingress:
      className: traefik
      controller: default
      annotations:
        kubernetes.io/ingress.class: traefik
        traefik.ingress.kubernetes.io/router.entrypoints: web,websecure
        traefik.ingress.kubernetes.io/router.middlewares: apps-harbor-redirect@kubernetescrd
        traefik.ingress.kubernetes.io/router.tls: "true"
        traefik.ingress.kubernetes.io/service.serverstransport: apps-harbor-transport@kubernetescrd
        # external-dns.alpha.kubernetes.io/hostname: harbor.m0sh1.cc
      hosts:
        core: harbor.m0sh1.cc
    notary:
      enabled: false
  externalURL: https://harbor.m0sh1.cc

  secretKey: ""
  existingSecretSecretKey: harbor-core-secret
  existingSecretAdminPassword: harbor-admin
  existingSecretAdminPasswordKey: HARBOR_ADMIN_PASSWORD
  database:
    type: external
    external:
      host: harbor-postgres-rw.apps.svc.cluster.local
      port: "5432"
      username: harbor
      coreDatabase: harbor
      existingSecret: harbor-postgres-auth
      sslmode: "disable"
    maxIdleConns: 20
    maxOpenConns: 100

  quotaUpdateProvider: redis

  persistence:
    enabled: true
    persistentVolumeClaim:
      registry:
        existingClaim: ""
      jobservice:
        jobLog:
          existingClaim: harbor-jobservice
      trivy:
        existingClaim: harbor-trivy
    imageChartStorage:
      disableredirect: true
      caBundleSecretName: minio-ca
      type: s3
      s3:
        existingSecret: harbor-registry-s3
        region: us-east-1
        bucket: harbor-registry
        regionendpoint: https://minio.minio-tenant.svc.cluster.local:443
        secure: true
        v4auth: true

  chartmuseum:
    enabled: false

  notary:
    enabled: false

  portal:
    replicas: 2
    revisionHistoryLimit: 1
    resources:
      requests:
        cpu: 100m
        memory: 256Mi
      limits:
        cpu: 500m
        memory: 512Mi
    nodeSelector:
      node-role.kubernetes.io/worker: "true"
    tolerations: []
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 80
          preference:
            matchExpressions:
            - key: topology.kubernetes.io/zone
              operator: In
              values: [ "pve-01" ]
        - weight: 60
          preference:
            matchExpressions:
            - key: topology.kubernetes.io/zone
              operator: In
              values: [ "pve-02" ]

  core:
    replicas: 2
    revisionHistoryLimit: 1
    existingSecret: harbor-core-internal
    resources:
      requests:
        cpu: 300m
        memory: 768Mi
      limits:
        cpu: 1
        memory: 1536Mi
    nodeSelector:
      node-role.kubernetes.io/worker: "true"
    tolerations: []
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 80
          preference:
            matchExpressions:
            - key: topology.kubernetes.io/zone
              operator: In
              values: [ "pve-01" ]
        - weight: 60
          preference:
            matchExpressions:
            - key: topology.kubernetes.io/zone
              operator: In
              values: [ "pve-02" ]

  jobservice:
    replicas: 1
    revisionHistoryLimit: 1
    existingSecret: harbor-jobservice-internal
    existingSecretKey: JOBSERVICE_SECRET
    resources:
      requests:
        cpu: 200m
        memory: 256Mi
      limits:
        cpu: 1
        memory: 1Gi
    nodeSelector:
      node-role.kubernetes.io/worker: "true"
    tolerations: []
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 80
          preference:
            matchExpressions:
            - key: topology.kubernetes.io/zone
              operator: In
              values: [ "pve-01" ]
        - weight: 60
          preference:
            matchExpressions:
            - key: topology.kubernetes.io/zone
              operator: In
              values: [ "pve-02" ]

  registry:
    replicas: 2
    revisionHistoryLimit: 1
    secret: ""
    existingSecret: ""
    credentials:
      username: harbor_registry_user
      existingSecret: harbor-registry-credentials
    registry:
      resources:
        requests:
          cpu: 200m
          memory: 512Mi
        limits:
          cpu: 1
          memory: 1Gi
    controller:
      resources:
        requests:
          cpu: 200m
          memory: 256Mi
        limits:
          cpu: 1
          memory: 1Gi
    nodeSelector:
      node-role.kubernetes.io/worker: "true"
    tolerations: []
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 80
          preference:
            matchExpressions:
            - key: topology.kubernetes.io/zone
              operator: In
              values: [ "pve-01" ]
        - weight: 60
          preference:
            matchExpressions:
            - key: topology.kubernetes.io/zone
              operator: In
              values: [ "pve-02" ]
    storage:
      filesystem:
        rootdirectory: /storage
        # See persistence.registry.persistentVolumeClaim settings above.
      redirect:
        disable: true

  trivy:
    enabled: true
    image:
      tag: v2.14.2
    replicas: 1
    revisionHistoryLimit: 1
    resources:
      requests:
        cpu: 300m
        memory: 512Mi
      limits:
        cpu: 1
        memory: 1Gi
    nodeSelector:
      node-role.kubernetes.io/worker: "true"
    tolerations: []
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 80
          preference:
            matchExpressions:
            - key: topology.kubernetes.io/zone
              operator: In
              values: [ "pve-01" ]
        - weight: 60
          preference:
            matchExpressions:
            - key: topology.kubernetes.io/zone
              operator: In
              values: [ "pve-02" ]

  redis:
    type: external
    external:
      addr: valkey.apps.svc.cluster.local:6379
      existingKey: harbor-valkey
      # keys depend on your sealed secret content; keep as-is if chart expects username/password

  updateStrategy:
    # Use Recreate so PVC-backed pods like registry/jobservice are stopped
    # before replacements attach the same volume.
    type: Recreate

migration:
  pvcs:
    enabled: false
    registry:
      name: harbor-registry
      storageClass: proxmox-csi-zfs-sata-object-retain
      size: 100Gi
      accessMode: ReadWriteOnce
    jobservice:
      name: harbor-jobservice
      storageClass: proxmox-csi-zfs-nvme-fast-retain
      size: 5Gi
    database:
      name: harbor-database
      storageClass: proxmox-csi-zfs-nvme-fast-retain
      size: 5Gi
    trivy:
      name: harbor-trivy
      storageClass: proxmox-csi-zfs-nvme-fast-retain
      size: 20Gi

serversTransport:
  forwardingTimeouts:
    dialTimeout: 30s
    responseHeaderTimeout: 10m
    idleConnTimeout: 10m

bootstrap:
  enabled: true
  image:
    repository: dhi.io/python
    tag: "3.14.3-alpine3.23-dev"
  backoffLimit: 6
  ttlSecondsAfterFinished: 3600
  nodeSelector:
    kubernetes.io/hostname: horse01
  resources:
    requests:
      cpu: 250m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 512Mi
  # External hostname used for image pulls/logins created by the bootstrap job.
  registryHost: harbor.m0sh1.cc
  proxyCaches:
  - name: hub
    registryName: hub
    registryType: docker-hub
    url: https://registry-1.docker.io
    public: true
    autoScan: true
    robots:
    - name: proxy-hub-pull
      description: Pull-only robot for Docker Hub proxy cache
      access:
      - pull
  - name: ghcr
    registryName: ghcr
    registryType: docker-registry
    url: https://ghcr.io
    public: true
    autoScan: true
    robots:
    - name: proxy-ghcr-pull
      description: Pull-only robot for GHCR proxy cache
      access:
      - pull
  - name: quay
    registryName: quay
    registryType: docker-registry
    url: https://quay.io
    public: true
    autoScan: true
    robots:
    - name: proxy-quay-pull
      description: Pull-only robot for Quay proxy cache
      access:
      - pull
  - name: k8s
    registryName: k8s
    registryType: docker-registry
    url: https://registry.k8s.io
    public: true
    autoScan: true
    robots:
    - name: proxy-k8s-pull
      description: Pull-only robot for registry.k8s.io proxy cache
      access:
      - pull
  - name: dhi
    registryName: dhi
    registryType: docker-registry
    url: https://dhi.io
    public: true
    autoScan: true
    robots:
    - name: proxy-dhi-pull
      description: Pull-only robot for dhi.io proxy cache
      access:
      - pull
  projects:
  - name: apps
    public: true
    autoScan: true
    robots:
    - name: gitea
      description: CI push/pull from Gitea runners
      access:
      - push
      - pull
    - name: build
      description: CI push/pull from app image builds
      access:
      - push
      - pull
  - name: base
    public: true
    autoScan: true
    robots:
    - name: build
      description: CI push/pull from base image builds
      access:
      - push
      - pull
  users:
  - name: build
    fullName: Harbor Build User
    email: build@m0sh1.cc
    comment: CI user with multi-project access
    passwordSecret: harbor-build-user
    usernameKey: username
    passwordKey: password
    dockerSecretName: harbor-user-build
    projects:
    - name: apps
      roleId: 2
    - name: base
      roleId: 2
    - name: hub
      roleId: 2
    - name: ghcr
      roleId: 2
    - name: quay
      roleId: 2
    - name: k8s
      roleId: 2
    - name: dhi
      roleId: 2

redisOperator:
  enabled: false
